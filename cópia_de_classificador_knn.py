# -*- coding: utf-8 -*-
"""Cópia de classificador-knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nLOBcKxuQI6aNeFEqRdKq9Euw-lVI3gE

## Objetivos

  - Apresentar e utilizar o classificador k-nearest neighbours (kNN)
  - Apresentar a técnica de separação de dados (treino e teste)
  - Avaliar Aprendizagem do modelo

## Começando

Vamos dar continuidade ao nosso estudo de aprendizagem de máquina, já vimos:

 - Tudo começa, conhecendo os dados disponíveis.
 - Como carregar um data frame
 - Como visualizar os dados em gráficos (histograma, box plot, violin plot, matriz de confusão)
 - Fizemos uma breve introdução sobre análise exploratória buscando correlacionar os dados para gerar informações.

 Hoje, vamos seguir nossa jornada e finalizar nosso estudo aplicando a técnica de KNN.

## k-Nearest Neighbors

O KNN(K vizinhos mais próximos) é considerado um dos algoritmos mais simples dentro da categoria de ***aprendizagem supervisionada*** sendo muito utilizado para problemas de classificação, porém também pode ser utilizado em problemas de regressão.

***Problemas de classificação*** = Vale lembrar que em problemas de classificação não estamos interessados em valores exatos, queremos apenas saber se um dado pertence ou não a uma dada classe.

### Uma intuição sobre o método

Para realizar a classificação o KNN calcula a distância objeto desconhecido (target) para todos os outros elementos, encontra os mais K vizinhos mais próximos faz uma contagem dos rótulos e considera que o objeto desconhecido pertence ao rótulo de maior contagem.

A imagem abaixo exemplifica o funcionamento, mas se ficou um pouco complicado de entender, rode o script python ***iknn.py*** e faça algumas simulações para compreender.



![knn](/aulas/lab02/knn.png)
<img src="https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab02/knn.png?raw=1">

## Bora lá!!

Vamos juntos realizar nosso primeiro projeto, do começo ao fim, de aprendizagem de máquina.

## Definição do problema

A primeira coisa que precisamos fazer é a definição do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da última aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar sua espécie com base nos dimensionais da pétala.

São 150 exemplares de flor de íris, pertencentes a três espécies diferentes: **setosa**, **versicolor** e **virginica**, sendo 50 amostras de cada espécie. Os atributos de largura e comprimento de sépala e largura e comprimento de pétala de cada flor fooram medidos manualmente.

<img src="https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png">

### Desafio 1

Do ponto de vista de machine learning, que problema é esse:

    Aprendizado supervisionado ou não-supervisionado?


R: Supervisionado, depende de acompanhamento humano

    Classificação ou regressão?

R: Classificação
"""

### R1: Supervisionado

## R2: De classificação

# Commented out IPython magic to ensure Python compatibility.
# Inicializção das bibliotecas
# %matplotlib inline

import pandas as pd
import matplotlib.pyplot as plt

# Caminho do arquivo
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
# Define o nome das colunas
header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
# Lê e carrega o arquivo para a memória
df = pd.read_csv(url, header=None, names=header)

# Retorna um trecho com as 5 primeiras linhas do dataframe
df.head()

df.tail()

# Mostra informações sobre o dataframe em si
df.info()

# class distribution
print(df.groupby('species').size())

"""### Desafio 2

Aplique os métodos que achar conveniente (vimos algumas opções na última aula) para visualizar os dados de forma gráfica.

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Caminho do arquivo
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"

# Define o nome das colunas

header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']

# Lê e carrega o arquivo para a memória

df = pd.read_csv(url, header=None, names=header)

# Pairplot para visualização multivariada
sns.pairplot(df, hue='species', height=3, aspect=1.2, palette='Set2')
plt.suptitle('Pairplot para Conjunto de Dados Iris', y=1.02)
plt.show()

# Heatmap de correlação
correlacao = df.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlacao, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap de Correlação para Conjunto de Dados Iris')
plt.show()

# Boxplot para cada variável em relação às espécies
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, palette='Set2')
plt.title('Boxplot para Conjunto de Dados Iris')
plt.xticks(rotation=45)
plt.show()

"""## PARE!!!

A análise feita no desafio 2 é uma das etapas mais importantes. Caso você tenha pulado essa etapa, volte e faça suas análises.

Com essa etapa concluída, vamos criar um sub-dataset com os atributos que serão utilizados.

"""

# Selecionando um sub-dataframe com os campos petal_length e petal_width,
# e outro com a variável de classes
entradas = df[['petal_length', 'petal_width']]
classes = df['species']
print(f"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}")

"""## Dividindo os dados em conjunto de treinamento e de testes

Dividir nosso dataset em dois conjuntos de dados.
    
    Treinamento - Representa 80% das amostras do conjunto de dados original,
    Teste - com 20% das amostras

Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a função ***train_test_split()***

***scikit-learn***: pip3 install scikit-learn


"""

# Separamos 20% para o teste
from sklearn.model_selection import train_test_split

entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)

print(f"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}")

#Primeiras linhas do dataframe
entradas_treino.head()

classes_treino.head()

"""## Chegou a hora de aplicar o modelo preditivo

Treinar um modelo no python é simples se usar o Scikit-Learn.
Treinar um modelo no Scikit-Learn é simples: basta criar o classificador, e chamar o método fit().

Uma observação sobre a sintaxe dos classificadores do `scikit-learn`
- O método `fit(X,Y)` recebe uma matriz ou dataframe X onde cada linha é uma amostra de aprendizado, e um array Y contendo as saídas esperadas do classificador, seja na forma de texto ou de inteiros
- O método `predict(X)` recebe uma matriz ou dataframe X onde cada linha é uma amostra de teste, retornando um array de classes


"""

# Importa a biblioteca
from sklearn.neighbors import KNeighborsClassifier

# Cria o classificar KNN
k = 9
modelo = KNeighborsClassifier(n_neighbors=k)

# Cria o modelo de machine learning
modelo.fit(entradas_treino, classes_treino)

"""Pronto!! bora testar se esta funcionando....

"""

# Para obter as previsões, basta chamar o método predict()
classes_encontradas = modelo.predict(entradas_teste)
print("Predição: {}".format(classes_encontradas))

# Para determinar a quantidade de acertos (acuracia)

from sklearn.metrics import accuracy_score
acertos = accuracy_score(classes_teste, classes_encontradas)
print("Acerto médio de classificação: ", acertos)

"""## Utilizando o modelo treinado com amostras fora do dataset

Vamos colocar alguns valores e ver a predição do classificador.
"""

# Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo faça a predição.

modelo.predict([[3.3, 3.2]])

"""## Visualizando o modelo de forma gráfica"""

# Unificamos os dados de entrada e as classes de treino e teste em um daframe cada
df_treino = pd.concat((entradas_treino, classes_treino), axis=1)

novas_classes = pd.Series(classes_encontradas, name="species", index=entradas_teste.index)
df_teste = pd.concat((entradas_teste, novas_classes), axis=1)

import seaborn as sns
## Unificamos os dataframes de treinamento e teste em um novo DataFrame
# indicando a origem dos dados
novo_df = pd.concat((df_treino, df_teste), keys=['train', 'test'])
novo_df['origin'] = ''
novo_df.loc['train','origin'] = 'Treino'
novo_df.loc['test','origin'] = 'Teste'

# Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado
sns.scatterplot('petal_length', 'petal_width', hue='species', style='origin', data=novo_df)

plt.show()

"""### Desafio 3

Fizemos o treinamento para k=3, mude o valor de k e análise a acurácia do modelo.

Dica: Faça um loop for que varre um range de k, a saída pode ser armazenada em uma lista. No final do loop exiba em um gráfico.


"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Carregar os dados
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
df = pd.read_csv(url, header=None, names=header)

# Separar entradas e classes
entradas = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]
classes = df['species']

# Dividir dados em conjuntos de treino e teste
entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.3, random_state=42)

# Criar o classificador KNN com k=3
k = 3
modelo = KNeighborsClassifier(n_neighbors=k)

# Treinar o modelo
modelo.fit(entradas_treino, classes_treino)

# Fazer uma predição com dados de teste
predicoes = modelo.predict(entradas_teste)

# Calcular a acurácia
acuracia = accuracy_score(classes_teste, predicoes)
print(f'Acurácia do modelo: {acuracia}')

# Scatterplot para visualização
novo_df = pd.concat((entradas_treino, classes_treino), keys=['train'])
novo_df['origin'] = 'Treino'

novas_classes = pd.Series(classes_teste, name="species", index=entradas_teste.index)
df_teste = pd.concat((entradas_teste, novas_classes), axis=1)
df_teste['origin'] = 'Teste'

novo_df = novo_df.append(df_teste.set_index('origin', append=True))

# Lista para armazenar as acurácias
acuracias = []

# Loop for para variar o valor de k de 1 a 20
for k in range(1, 21):
    # Criar o classificador KNN
    modelo = KNeighborsClassifier(n_neighbors=k)

    # Treinar o modelo
    modelo.fit(entradas_treino, classes_treino)

    # Fazer uma predição com dados de teste
    predicoes = modelo.predict(entradas_teste)

    # Calcular a acurácia e armazenar na lista
    acuracia = accuracy_score(classes_teste, predicoes)
    acuracias.append(acuracia)

# Scatterplot para visualizar acurácias em função de k
plt.figure(figsize=(10, 6))
plt.plot(range(1, 21), acuracias, marker='o', linestyle='dashed', color='b', markerfacecolor='r', markersize=10)
plt.title('Acurácia em Função de k (Vizinhos)')
plt.xlabel('Número de Vizinhos (k)')
plt.ylabel('Acurácia')
plt.xticks(range(1, 21))
plt.grid(True)
plt.show()

#### Resposta loop for para diferntes k
k_range = list(range(1,26))
acertos = []
for k in k_range:
    modelo = KNeighborsClassifier(n_neighbors=k)
    modelo.fit(entradas_treino, classes_treino)
    classes_encontradas = modelo.predict(entradas_teste)
    acertos.append(accuracy_score(classes_teste, classes_encontradas))


plt.plot(k_range, acertos)
plt.xlabel('Valor de k do KNN')
plt.ylabel('Taxa de acertos')
plt.title('Taxa de acertos x valor de k do KNN')
plt.show()

"""### Desafio 4

Refaça os notebook substituindo as entradas (variaveis independentes) e analise se o modelo obtido ficou melhor ou pior.



"""

# R. 4 Ao modificar as entradas, reduzindo-as somente para os dados das séplas, a acurácia do modelo classificatório diminui.

## implemente sua sua solução....
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Carregar os dados
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
df = pd.read_csv(url, header=None, names=header)

# Selecionar novas entradas (sepal_length e sepal_width)
novas_entradas = df[['sepal_length', 'sepal_width']]

# Separar as novas entradas e classes
entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(novas_entradas, df['species'], test_size=0.3, random_state=42)

# Lista para armazenar as acurácias
acuracias = []

# Loop for para variar o valor de k de 1 a 20
for k in range(1, 21):
    # Criar o classificador KNN
    modelo = KNeighborsClassifier(n_neighbors=k)

    # Treinar o modelo
    modelo.fit(entradas_treino, classes_treino)

    # Fazer uma predição com dados de teste
    predicoes = modelo.predict(entradas_teste)

    # Calcular a acurácia e armazenar na lista
    acuracia = accuracy_score(classes_teste, predicoes)
    acuracias.append(acuracia)

# Scatterplot para visualizar acurácias em função de k
plt.figure(figsize=(10, 6))
plt.plot(range(1, 21), acuracias, marker='o', linestyle='dashed', color='b', markerfacecolor='r', markersize=10)
plt.title('Acurácia em Função de k (Vizinhos)')
plt.xlabel('Número de Vizinhos (k)')
plt.ylabel('Acurácia')
plt.xticks(range(1, 21))
plt.grid(True)
plt.show()

"""### Desafio 5

Lembra o dataset 'breast_cancer', faça um modelo de predição que informa se o câncer é maligno ou não.

"""

import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Carregar os dados
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data"

# Definir os nomes das colunas
nomes_colunas = ['Class', 'Age', 'Menopause', 'Tumor Size', 'Inv Nodes', 'Node Caps',
                 'Deg Malig', 'Breast', 'Breast Quad', 'Irradiat']

# Lê e carrega o arquivo para a memória, utilizando os nomes das colunas fornecidos
df = pd.read_csv(url, header=None, names=nomes_colunas)

# Converte a coluna 'Class' para valores numéricos (0 para benigno, 1 para maligno)
df['Class'] = df['Class'].apply(lambda x: 1 if x == 'malignant' else 0)

# Convertendo variáveis categóricas em variáveis dummy (one-hot encoding)
df_encoded = pd.get_dummies(df, columns=['Age', 'Menopause', 'Tumor Size', 'Inv Nodes', 'Node Caps', 'Breast', 'Breast Quad', 'Irradiat'])

# Selecionar as variáveis independentes (features) e a variável dependente (target)
entradas = df_encoded.drop('Class', axis=1)
classes = df_encoded['Class']

# Dividir dados em conjuntos de treino e teste
entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.3, random_state=42)

# Criar o classificador KNN com k=3
k = 3
modelo = KNeighborsClassifier(n_neighbors=k)

# Treinar o modelo
modelo.fit(entradas_treino, classes_treino)

# Fazer uma predição com dados de teste
predicoes = modelo.predict(entradas_teste)

# Calcular a acurácia
acuracia = accuracy_score(classes_teste, predicoes)
print(f'Acurácia do modelo: {acuracia}')